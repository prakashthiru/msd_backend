{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, count, rank, row_number, unix_timestamp\n",
    "from walrus import *\n",
    "\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naming Constants\n",
    "key_joiner = ':'\n",
    "\n",
    "recent_key_meta = 'recent'\n",
    "count_key_meta = 'count'\n",
    "color_key_meta = 'color'\n",
    "\n",
    "# Application Constants\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.load(f)\n",
    "\n",
    "recent_data_count = config['recent_data_count']\n",
    "color_data_count = config['color_data_count']\n",
    "\n",
    "required_columns = config['required_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connecting Redis Database\n",
    "db = Database(host = config['redisdb']['host'], port = config['redisdb']['port'], db = config['redisdb']['db'])\n",
    "\n",
    "# To execute operations in cluster\n",
    "spark = SparkSession \\\n",
    "                  .builder \\\n",
    "                  .appName('analytics') \\\n",
    "                  .master(\"local[*]\") \\\n",
    "                  .getOrCreate();\n",
    "\n",
    "# Loading data as spark DF. Column with dots -> Upgrade pyspark > 2.0.0\n",
    "session_df = spark.read \\\n",
    "                  .option(\"delimiter\", \",\") \\\n",
    "                  .option(\"inferSchema\", \"true\") \\\n",
    "                  .option(\"header\", config['data_headers']) \\\n",
    "                  .csv(config['data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data clean up\n",
    "\n",
    "# # REMOVE DUPLICATE RECORDS AND IF A COLUMN HAS NULL VALUE\n",
    "# clean_df = session_df.dropna() \\\n",
    "#                     .dropDuplicates() \\\n",
    "#                     .select(required_columns)\n",
    "min_df = session_df.select(required_columns)\n",
    "clean_df = min_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# API II - /getBrandsCount\n",
    "\n",
    "count_df = clean_df.withColumn('date_added', unix_timestamp(clean_df.dateAdded.cast('date'))) \\\n",
    "                    .groupBy('date_added', 'brand') \\\n",
    "                    .agg(count('brand')) \\\n",
    "                    .orderBy('date_added', 'count(brand)', ascending=False)\n",
    "\n",
    "count_dict = count_df.toPandas() \\\n",
    "                      .groupby('date_added') \\\n",
    "                      .apply(lambda x: dict(zip(x['brand'], x['count(brand)']))) \\\n",
    "                      .to_dict()\n",
    "\n",
    "for epoch_date, data in count_dict.iteritems():\n",
    "    count_key = count_key_meta + key_joiner + str(epoch_date)\n",
    "\n",
    "    if db.exists(count_key):\n",
    "        count_hash = db.get_key(count_key)\n",
    "    else:\n",
    "        count_hash = db.Hash(count_key)\n",
    "\n",
    "    count_hash.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API III - /getItemsbyColor\n",
    "\n",
    "color_window = Window.partitionBy(clean_df.colors) \\\n",
    "                    .orderBy(clean_df.dateAdded.desc(), clean_df.dateUpdated.desc())\n",
    "\n",
    "color_df = clean_df.select('*', row_number() \\\n",
    "                                .over(color_window) \\\n",
    "                                .alias('row_number')) \\\n",
    "                    .filter(col('row_number') <= color_data_count) \\\n",
    "                    .drop('row_number')\n",
    "\n",
    "color_dict = color_df.toPandas() \\\n",
    "                    .groupby(['colors']) \\\n",
    "                    .apply(lambda x: x.to_dict('records'))\n",
    "\n",
    "for color, data in color_dict.iteritems():\n",
    "    split_colors = color.split(',')\n",
    "\n",
    "    for split_color in split_colors:\n",
    "        color_key = (color_key_meta + key_joiner + split_color).lower()\n",
    "\n",
    "        if db.exists(color_key):\n",
    "            color_hash = db.get_key(color_key)\n",
    "        else:\n",
    "            color_hash = db.List(color_key)\n",
    "\n",
    "        color_hash.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API I - /getRecentItem\n",
    "\n",
    "date_window = Window.partitionBy(clean_df.dateAdded) \\\n",
    "                    .orderBy(clean_df.dateAdded.desc(), clean_df.dateUpdated.desc())\n",
    "\n",
    "recent_df = clean_df.withColumn('date_added', unix_timestamp(clean_df.dateAdded.cast('date'))) \\\n",
    "                    .withColumn('row_number', row_number().over(date_window)) \\\n",
    "                    .filter(col('row_number') == recent_data_count) \\\n",
    "                    .drop('row_number')\n",
    "\n",
    "recent_dict = recent_df.toPandas().to_dict('records')\n",
    "\n",
    "for data in recent_dict:\n",
    "    recent_key = recent_key_meta + key_joiner + str(data['date_added'])\n",
    "\n",
    "    if db.exists(recent_key):\n",
    "        recent_hash = db.get_key(recent_key)\n",
    "    else:\n",
    "        recent_hash = db.Hash(recent_key)\n",
    "\n",
    "    recent_hash.update(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
